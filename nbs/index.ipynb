{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev_squ import api, clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEM Query Utils\n",
    "\n",
    "> Python SIEM Query Utils nbdev edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install nbdev_squ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using, config needs to be loaded into `squ.core.cache`, which can be done automatically from json in a keyvault by setting the env var `SQU_CONFIG` to `\"keyvault/tenantid\"`.\n",
    "\n",
    "```bash\n",
    "export SQU_CONFIG=\"{{ keyvault }}/{{ tenantid }}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev_squ import api\n",
    "import io, pandas\n",
    "\n",
    "# Load workspace info from datalake blob storage\n",
    "df = api.list_workspaces(fmt=\"df\"); print(df.shape)\n",
    "\n",
    "# Load workspace info from introspection of azure graph\n",
    "df = api.list_securityinsights(); print(df.shape)\n",
    "\n",
    "# Kusto query to Sentinel workspaces via Azure Lighthouse\n",
    "df = api.query_all(\"SecurityIncident | take 20\", fmt=\"df\"); print(df.shape)\n",
    "\n",
    "# Kusto queries to Sentinel workspaces via Azure Lighthouse (batches up to 100 queries at a time)\n",
    "df = api.query_all([\"SecurityAlert | take 20\" for a in range(10)]); print(df.shape)\n",
    "\n",
    "# Kusto query to ADX\n",
    "#df = api.adxtable2df(api.adx_query(\"kusto query | take 20\"))\n",
    "\n",
    "# General azure cli cmd\n",
    "api.azcli([\"config\", \"set\", \"extension.use_dynamic_install=yes_without_prompt\"])\n",
    "print(len(api.azcli([\"account\", \"list\"])))\n",
    "\n",
    "# Various pre-configured api clients\n",
    "\n",
    "# RunZero\n",
    "response = api.clients.runzero.get(\"/export/org/assets.csv\", params={\"search\": \"has_public:t AND alive:t AND (protocol:rdp OR protocol:vnc OR protocol:teamviewer OR protocol:telnet OR protocol:ftp)\"})\n",
    "pandas.read_csv(io.StringIO(response.text)).head(10)\n",
    "\n",
    "# Jira\n",
    "pandas.json_normalize(api.clients.jira.jql(\"updated > -1d\")[\"issues\"]).head(10)\n",
    "\n",
    "# AbuseIPDB\n",
    "api.clients.abuseipdb.check_ip(\"1.1.1.1\")\n",
    "\n",
    "# TenableIO\n",
    "pandas.DataFrame(api.clients.tio.scans.list()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badips_df = api.query_all(\"\"\"\n",
    "SecurityIncident\n",
    "| where Classification == \"TruePositive\"\n",
    "| mv-expand AlertIds\n",
    "| project tostring(AlertIds)\n",
    "| join SecurityAlert on $left.AlertIds == $right.SystemAlertId\n",
    "| mv-expand todynamic(Entities)\n",
    "| project Entities.Address\n",
    "| where isnotempty(Entities_Address)\n",
    "| distinct tostring(Entities_Address)\n",
    "\"\"\", timespan=pandas.Timedelta(\"45d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = api.query_all(\"find where ClientIP startswith '172.16.' | evaluate bag_unpack(pack_) | take 40000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = api.query_all(\"\"\"union withsource=\"_table\" *\n",
    "| extend _ingestion_time_bin = bin(ingestion_time(), 1h)\n",
    "| summarize take_any(*) by _table, _ingestion_time_bin\n",
    "| project pack=pack_all(true)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pandas.DataFrame(list(df[\"pack\"].apply(json.loads)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
