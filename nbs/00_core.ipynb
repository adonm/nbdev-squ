{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "A set of core functions and a wrapper for the azure cli and some other azure apis, which simplifies authentication and retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import logging, subprocess, os, sys, pandas\n",
    "from platformdirs import PlatformDirs\n",
    "from diskcache import Cache, memoize_stampede\n",
    "from tenacity import wait_random_exponential, stop_after_attempt, Retrying\n",
    "from upath import UPath\n",
    "from benedict import benedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching and retry helpers\n",
    "The below `cache` sets up a persistent per user disk cache (to ensure security) that can be used throughout api setup and configuration. `retryer` will try to run a function again up to 3 times with a random exponential backoff to handle upstream api exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "dirs = PlatformDirs(\"nbdev-squ\")\n",
    "cache = Cache(dirs.user_cache_dir)\n",
    "retryer = Retrying(wait=wait_random_exponential(), stop=stop_after_attempt(3), reraise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _cli(cmd: list[str], capture_output=True):\n",
    "    cmd = [sys.executable, \"-m\", \"azure.cli\"] + cmd\n",
    "    if capture_output: # Try lots, parse output as json\n",
    "        try:\n",
    "            result = retryer(subprocess.run, cmd + [\"-o\", \"json\"], capture_output=capture_output, check=True, text=True)\n",
    "        except subprocess.CalledProcessError:\n",
    "            # Clear login cache incase stale\n",
    "            cache.delete(\"logged_in\")\n",
    "            # Run in foreground to see error\n",
    "            subprocess.run(cmd, check=True)\n",
    "        try:\n",
    "            result = benedict(result.stdout, format=\"json\")\n",
    "        except ValueError: # handle if output not json\n",
    "            logger.info(\"Falling back to plain cli output\")\n",
    "            result = result.stdout.strip().strip('\"') or benedict()\n",
    "        return result\n",
    "    else: # Run interactively, ignore success/fail\n",
    "        subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login and secrets management\n",
    "The squ library depends on authentication configured and ready to go. There are 2 paths to login used based on environment variables available. Once logged in it will attempt to populate `cache[\"config\"]` with secrets from a configuration keyvault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def load_config(path = None # Path to read json config into cache from\n",
    "               ):\n",
    "    config = benedict()\n",
    "    if path:\n",
    "        config = benedict(path.read_text(), format=\"json\")\n",
    "    try:\n",
    "        _cli([\"config\", \"set\", \"extension.use_dynamic_install=yes_without_prompt\"])\n",
    "        config = benedict(_cli([\"keyvault\", \"secret\", \"show\", \n",
    "                                \"--vault-name\", cache[\"vault_name\"], \n",
    "                                \"--name\", f\"squconfig-{cache['tenant_id']}\"]).value, format=\"json\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        cache.delete(\"logged_in\") # clear the logged in state\n",
    "    config.standardize()\n",
    "    return config\n",
    "\n",
    "def login(refresh: bool=False # Force relogin\n",
    "         ):\n",
    "    if \"/\" in os.environ.get(\"SQU_CONFIG\", \"\"):\n",
    "        cache[\"vault_name\"], cache[\"tenant_id\"] = os.environ[\"SQU_CONFIG\"].split(\"/\")\n",
    "    tenant = cache.get(\"tenant_id\")\n",
    "    try:\n",
    "        _cli([\"account\", \"show\"])\n",
    "        if tenant:\n",
    "            tenant_visible = len(_cli([\"account\", \"list\"]).search(tenant)) > 0\n",
    "            assert tenant_visible > 0\n",
    "        cache.set(\"logged_in\", True, 60 * 60 * 3) # cache login state for 3 hrs\n",
    "    except:\n",
    "        cache.delete(\"logged_in\")\n",
    "    while not cache.get(\"logged_in\"):\n",
    "        logger.info(\"Cache doesn't look logged in, attempting login\")\n",
    "        try:\n",
    "            # See if we can login with a managed identity in under 5 secs and see the configured tenant\n",
    "            subprocess.run([\"timeout\", \"5\", sys.executable, \"-m\", \"azure.cli\", \"login\", \"--identity\", \"-o\", \"none\", \"--allow-no-subscriptions\"], check=True)\n",
    "            if tenant:\n",
    "                tenant_visible = len(_cli([\"account\", \"list\"]).search(tenant)) > 0\n",
    "                assert tenant_visible > 0\n",
    "        except:\n",
    "            # If managed identity unavailable, fall back on a manual login\n",
    "            if tenant:\n",
    "                tenant_scope = [\"--tenant\", tenant]\n",
    "            else:\n",
    "                tenant_scope = []\n",
    "            _cli([\"login\", *tenant_scope, \"--use-device-code\", \"--allow-no-subscriptions\", \"-o\", \"none\"], capture_output=False)\n",
    "        # Finally, validate the login once more, and set the login state\n",
    "        try:\n",
    "            _cli([\"account\", \"show\"])\n",
    "            cache.set(\"logged_in\", True, 60 * 60 * 3) # cache login state for 3 hrs\n",
    "        except subprocess.CalledProcessError:\n",
    "            cache.delete(\"logged_in\")\n",
    "    logger.info(\"Cache state is logged in\")\n",
    "    if cache.get(\"vault_name\"): # Always reload config on any login call\n",
    "        logger.info(\"Loading config from keyvault\")\n",
    "        cache[\"config\"] = load_config() # Config lasts forever, don't expire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to login\n",
    "The login function will be called automatically if the `azcli` function defined below is used and the cache has no login timestamp, otherwise it can be called manually as well to refresh the keyvault config items with `load_config` (this directly loads a keyvault secret into the cache based on the **SQU_CONFIG** environment variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login()\n",
    "cache[\"config\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def azcli(basecmd: list[str]):\n",
    "    if not cache.get(\"logged_in\"):\n",
    "        login()\n",
    "    return _cli(basecmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalake Path\n",
    "The `datalake_path` function below, returns a `UPath` pathlib style object pointing to a configured datalake location in the `cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache['config']['datalake_container']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@memoize_stampede(cache, expire=60 * 60 * 24)\n",
    "def datalake_path_safe(expiry_days, permissions):\n",
    "    if not cache.get(\"logged_in\"): # Have to login to grab keyvault config\n",
    "        login()\n",
    "    expiry = pandas.Timestamp(\"now\") + pandas.Timedelta(days=expiry_days)\n",
    "    account = cache[\"config\"][\"datalake_account\"].split(\".\")[0] # Grab the account name, not the full FQDN\n",
    "    container = cache['config']['datalake_container']\n",
    "    sas = azcli([\"storage\", \"container\", \"generate-sas\", \"--auth-mode\", \"login\", \"--as-user\",\n",
    "                 \"--account-name\", account, \"--name\", container, \"--permissions\", permissions, \"--expiry\", str(expiry.date())])\n",
    "    return (container, account, sas)\n",
    "\n",
    "def datalake_path(expiry_days: int=3, # Number of days until the SAS token expires\n",
    "                  permissions: str=\"racwdlt\" # Permissions to grant on the SAS token\n",
    "                    ):\n",
    "    container, account, sas = datalake_path_safe(expiry_days, permissions)\n",
    "    return UPath(f\"az://{container}\", account_name=account, sas_token=sas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datalake_path()\n",
    "print(\"\\n\".join([str(p) for p in path.ls()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
